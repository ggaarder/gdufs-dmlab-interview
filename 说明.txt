mission1:
    文件夹中有3个task的txt文件，在task1.txt每行结构如下：
    x   y   颜色(16进制)
    目标就是通过matplotlib或者pyecharts按照上面的点画出散点图，
    等画出散点图之后就可以看到一些有趣的现象了，请保留截图并描述你看到的现象。
    task2.txt和task3.txt与task1.txt格式一致
    注意：如果使用pyecharts画图的话，打开的时候浏览器需要的时间比较长，请耐心等待。
    建议尝试一下matplotlib

mission2:
    1.  请分别统计“射雕英雄传.txt”、“鹿鼎记.txt”、“笑傲江湖.txt”中所有人名出现的次数，
        若人名过多，取最重要的10个人名展示。
        并且画出统计直方图（柱状图），你可能需要用到停用词表“stopwords.txt”
        请保留截图并说出出现次数最多的10个人名。
        tips：使用jieba做分词和词性标注（识别人名），使用pyecharts或matplotlib作图。
    2.(拓展题)根据“射雕英雄传.txt”文本的内容，想办法对提取出的人名做一个相似度计算，
        计算出人名之间的两两相似度，并且有没有办法使用Kmeans对人名做一个聚类？。

mission3:
    现有北京房屋交易数据“beijing.csv”，包括交易id、交易时间、交易年月日等数据，
    请根据文件完成以下任务：
    1. 最高房价的成交记录和最低房价成交记录分别是在哪一年？总价多少？面积多少？
    2. 关注度最高的成交记录是哪一个？房子是怎么样的？
    3. 请分别统计各年度北京每平方米的房价均值，并且画出折线图（图1）。
    4. 请分别统计各年度北京靠近地铁和不靠近地铁的每平方米房价均值，并且在图1的基础上再画出两条折线。
    5. 哪个月份买房的人最多？哪个月份买房的人最少？每个月份购买的人数占比是多少？请画出饼状图。
    6. （拓展题）取出2017年12月的成交数据。尝试采用线性回归/多项式回归的方法预测房价？
        tips：相关知识：线性回归、梯度下降、多项式回归、均方误差
              相关工具包：sklearn、numpy

mission4：
    现有新闻数据news_simple.json，内有171篇新闻的标题和正文，请尝试根据标题和正文提取出每篇新闻的关键词。
    tips: 可以考虑采用tf-idf的方法提取（提取出tf-idf值最高的几个词）。
    为了降低难度，每篇新闻的关键词都在新闻中出现过，而且每篇新闻的关键词固定为4个。
    请提取出171篇新闻的关键词，并且按照如下格式输出至“outputs.txt”文件，编码为utf-8：

    第一篇新闻关键词1   第一篇新闻第2个关键词 第一篇新闻第3个关键词 第一篇新闻第3个关键词
    第二篇新闻关键词1   第二篇新闻第2个关键词 第二篇新闻第3个关键词 第二篇新闻第3个关键词
    ...

    关键词之间用"\t"隔开，可参考outputs_sample.txt的格式。输出完成后可以直接运行"evaluate.py"，
    即可得到评分结果，评分采用平均jaccard系数来衡量。评分值在0到1之间，越大越好。

    你可能需要使用比较大规模的语料库计算词的idf，这里我提供一个有10万篇新闻的数据：news_10W.txt
    news_10W.txt每行为一篇新闻的标题和正文，标题与正文之间用@隔开。由于数据集过大所以直接给出百度云
    https://pan.baidu.com/s/1iu6_qInffim7flsn-tCBtA
    提取码：fbvq
    如果觉得语料还不够大，群上说一声，我给你U盘拷贝









